{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import Dataset\n",
    "from   ModelLoader import ModelLoader\n",
    "from convnet import *\n",
    "import datetime\n",
    "import SimpleITK as sitk\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, fixed\n",
    "from myshow import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Testing TF GPU Support\n",
    "\n",
    "# Creates a graph.\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "test_sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(test_sess.run(c))\n",
    "test_sess.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "model = ModelLoader('models/model_6.json')\n",
    "\n",
    "data_manager = Dataset.DatasetManager(\n",
    "    train=model.get_config('train_data_path'),\n",
    "    test= model.get_config('test_data_path'),\n",
    "    target_shape=model.get_config('data_shape')\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = data_manager.get_current_dataset()\n",
    "random_tile(data_manager.get_current_dataset(), (7, 7))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "ds = data_manager.get_current_dataset()\n",
    "\n",
    "# Network Parameters\n",
    "data_shape = [ds.original_X_shape[1], ds.original_X_shape[2], ds.original_X_shape[3]]\n",
    "n_input   = ds.original_X_shape[1] * ds.original_X_shape[2] * ds.original_X_shape[3]   # Input size\n",
    "n_classes = model.get_config('n_classes')\n",
    "dropout   = model.get_config('dropout')\n",
    "\n",
    "# Parameters\n",
    "learning_rate  = model.get_config('learning_rate')\n",
    "training_iters = model.get_config('training_iters')\n",
    "batch_size     = model.get_config('batch_size')\n",
    "display_step   = model.get_config('display_step')\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "\n",
    "with tf.name_scope('dropout'):\n",
    "    keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "    tf.scalar_summary('dropout_keep_probability', keep_prob)\n",
    "    \n",
    "# Construct model\n",
    "W = model.get_weights()\n",
    "b = model.get_biases()\n",
    "pred = conv_net(x, data_shape, W, b, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    with tf.name_scope('total'):\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "        # L2 regularization for the fully connected parameters.\n",
    "        regularizers = (tf.nn.l2_loss(W['wd1']) + tf.nn.l2_loss(b['bd1']))\n",
    "          # Add the regularization term to the loss.\n",
    "        cost += 5e-4 * regularizers\n",
    "        tf.scalar_summary('reg_cost', 5e-4 * regularizers)\n",
    "        tf.scalar_summary('cost', cost)\n",
    "        \n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "with tf.name_scope('accuracy'):\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    tf.scalar_summary('accuracy', accuracy)\n",
    "\n",
    "# Initializing the variables\n",
    "merged = tf.merge_all_summaries()\n",
    "\n",
    "str_now = datetime.datetime.now().strftime(\"%d-%m-%Y#%H_%M_%S\")\n",
    "\n",
    "train_writer = tf.train.SummaryWriter('logs/train/' + '/' + model.get_config('id') + '/' + str_now, sess.graph)\n",
    "test_writer  = tf.train.SummaryWriter('logs/test/'  + '/' + model.get_config('id') + '/' + str_now, sess.graph)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)\n",
    "\n",
    "# Load test dataset\n",
    "test_dataset = data_manager.get_test_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = 8 * 25 * (64 * 64 * 64 * 1 ) + (5 * 5 * 5 * 1 * 12 ) + (5 * 5 * 5 * 12 * 12) + (8 * 8 * 8 * 12 * 256) + (256 * 2)\n",
    "\n",
    "x / (1024 * 1024  * 1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "    # Launch the graph\n",
    "step = 1\n",
    "\n",
    "with sess:\n",
    "    \n",
    "    test_batch_x, test_batch_y = test_dataset.next_batch(4)\n",
    "    test_dict = {\n",
    "        x: test_batch_x,\n",
    "        y: test_batch_y,\n",
    "        keep_prob: 1.0\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "\n",
    "        batch_x, batch_y = data_manager.next_batch(batch_size)\n",
    "        train_dict = {\n",
    "            x: batch_x, \n",
    "            y: batch_y, \n",
    "            keep_prob: 1.0\n",
    "        }\n",
    "                        \n",
    "        # Run optimization op (backprop)\n",
    "        summary, _ = sess.run([merged, optimizer], feed_dict=train_dict)\n",
    "        train_writer.add_summary(summary, step)\n",
    "\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            train_acc, train_loss = sess.run([accuracy, cost], feed_dict=train_dict)\n",
    "            summary, test_acc  = sess.run([merged, accuracy], feed_dict=test_dict)\n",
    "\n",
    "            test_writer.add_summary(summary, step)\n",
    "            # update_line(hl, [step*batch_size, train_loss])\n",
    "            print( \"Iter {0: >6}\".format(step * batch_size) + \n",
    "                \", Minibatch Loss = {:.6f}\".format(train_loss) + \n",
    "                \", Training Accuracy = {:.5f}\".format(train_acc) + \n",
    "                \", Test Accuracy = {:.5f}\".format(test_acc)\n",
    "             )\n",
    "\n",
    "        step += 1\n",
    "        \n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "train_writer.close()\n",
    "test_writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
