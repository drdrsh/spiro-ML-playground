{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import Dataset\n",
    "from convnet import *\n",
    "import datetime\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Testing TF GPU Support\n",
    "\n",
    "# Creates a graph.\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "test_sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(test_sess.run(c))\n",
    "test_sess.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(ds.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset ./Data/train/np/5/data_0.npy (sync) \n",
      "Loading dataset ./Data/train/np/5/data_0.npy (async) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-39:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mostafa/anaconda3/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/mostafa/SummerProject/Dataset.py\", line 155, in run\n",
      "    padding_size = self.target_shape[i] - X.shape[i + 1]\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "Exception in thread Thread-40:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mostafa/anaconda3/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/mostafa/SummerProject/Dataset.py\", line 155, in run\n",
      "    padding_size = self.target_shape[i] - X.shape[i + 1]\n",
      "IndexError: tuple index out of range\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_manager = Dataset.DatasetManager(\n",
    "    train='./Data/train/np/5/',\n",
    "    test ='./Data/test/np/5/', \n",
    "    target_shape=(150, 150, 150)\n",
    ")\n",
    "\n",
    "#data_manager = Dataset.DatasetManager(train=None, test=None, target_shape=(128, 128, 128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 128, 128]\n",
      "Input to Conv1 (?, 128, 128, 128, 1)\n",
      "Output of Conv1 (?, 128, 128, 128, 96)\n",
      "Input to MaxPool1 (?, 128, 128, 128, 96)\n",
      "Output of MaxPool1 (?, 62, 62, 62, 96)\n",
      "Input to Conv2 (?, 62, 62, 62, 96)\n",
      "Output of Conv2 (?, 62, 62, 62, 96)\n",
      "Input to MaxPool2 (?, 62, 62, 62, 96)\n",
      "Output to MaxPool2 (?, 29, 29, 29, 96)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "ds = data_manager.get_current_dataset()\n",
    "\n",
    "# Network Parameters\n",
    "data_shape = [ds.original_X_shape[1], ds.original_X_shape[2], ds.original_X_shape[3]]\n",
    "n_input = ds.original_X_shape[1] * ds.original_X_shape[2] * ds.original_X_shape[3]   # Input size\n",
    "n_classes = 2     # Classes (No Emphysema, Emphysema)\n",
    "dropout = 0.75    # Dropout, probability to keep units\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 400000\n",
    "batch_size = 25\n",
    "display_step = 10\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "\n",
    "with tf.name_scope('dropout'):\n",
    "    keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "    tf.scalar_summary('dropout_keep_probability', keep_prob)\n",
    "    \n",
    "    \n",
    "# Number of neurons = Output Volume Size \n",
    "# Number of biases = 1 Per neuron\n",
    "# Number of Bias terms = Number of Filters \n",
    "# Number of weights = FilterWidth*Fitlerheight*FiltherDepth*InputColors\n",
    "# Output Volume Size = (FilterWidth * padding * padding )\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # Filter Width, Filter Height, Filter Slices, Filter Depth (Image channels), Filter Count\n",
    "\n",
    "    # 96 Filters of shape 5x5x5x1\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 5, 1, 12])),\n",
    "    \n",
    "    # Due to padding the output size remains the same @ 64x64x64x12\n",
    "    # maxpool3d with k = 6 and stride= 2\n",
    "    # Output of maxpool3d = ( (64-6)/2 )  + 1 = 30\n",
    "    # Output volume 30x30x30x12 (Filter number remains the same after maxpooling)\n",
    "    'mp1': {'k':6, 's':2},\n",
    "    \n",
    "    # 12 Filters of shape 5x5x5x12\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 5, 12, 12])),\n",
    "\n",
    "    'mp2': {'k':6, 's':2},\n",
    "    \n",
    "    # Due to padding the output size remains the same @ 30x30x30x12\n",
    "    # maxpool3d with k = 6 and stride= 2\n",
    "    # Output of maxpool3d = ( (30-2)/2 ) + 1 = 15\n",
    "    # Output volume 15x15x15x12 (Filter number remains the same after maxpooling)\n",
    "\n",
    "    \n",
    "    # fully connected, 8*8*12 inputs, 256 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([8*8*8*12, 256])),\n",
    "    # 256 inputs, 2 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([256, n_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([12])),\n",
    "    'bc2': tf.Variable(tf.random_normal([12])),\n",
    "    'bd1': tf.Variable(tf.random_normal([256])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = conv_net(x, data_shape, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    with tf.name_scope('total'):\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "        tf.scalar_summary('cost', cost)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "with tf.name_scope('accuracy'):\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    tf.scalar_summary('accuracy', accuracy)\n",
    "\n",
    "# Initializing the variables\n",
    "merged = tf.merge_all_summaries()\n",
    "\n",
    "str_now = datetime.datetime.now().strftime(\"%d-%m-%Y#%H_%M_%S\")\n",
    "\n",
    "train_writer = tf.train.SummaryWriter('logs/train/' + str_now, sess.graph)\n",
    "test_writer  = tf.train.SummaryWriter('logs/test/'  + str_now, sess.graph)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)\n",
    "\n",
    "# Load test dataset\n",
    "test_dataset = data_manager.get_test_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.050311606377363205"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 8 * 25 * (64 * 64 * 64 * 1 ) + (5 * 5 * 5 * 1 * 12 ) + (5 * 5 * 5 * 12 * 12) + (8 * 8 * 8 * 12 * 256) + (256 * 2)\n",
    "\n",
    "x / (1024 * 1024  * 1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (2, 0) for Tensor 'Placeholder:0', which has shape '(?, 2097152)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-47e955e3a916>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# Run optimization op (backprop)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmerged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mtrain_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mostafa/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 382\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    383\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mostafa/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    638\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m    641\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (2, 0) for Tensor 'Placeholder:0', which has shape '(?, 2097152)'"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "step = 1\n",
    "\n",
    "with sess:\n",
    "    \n",
    "    test_batch_x, test_batch_y = test_dataset.next_batch(15)\n",
    "    test_dict = {\n",
    "        x: test_batch_x,\n",
    "        y: test_batch_y,\n",
    "        keep_prob: 1.0\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "\n",
    "        batch_x, batch_y = data_manager.next_batch(batch_size)\n",
    "        train_dict = {\n",
    "            x: batch_x, \n",
    "            y: batch_y, \n",
    "            keep_prob: 1.0\n",
    "        }\n",
    "                        \n",
    "        # Run optimization op (backprop)\n",
    "        summary, _ = sess.run([merged, optimizer], feed_dict=train_dict)\n",
    "        train_writer.add_summary(summary, step)\n",
    "\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            train_acc, train_loss = sess.run([accuracy, cost], feed_dict=train_dict)\n",
    "            summary, test_acc  = sess.run([merged, accuracy], feed_dict=test_dict)\n",
    "\n",
    "            test_writer.add_summary(summary, step)\n",
    "            \n",
    "            print( \"Iter \" + str(step * batch_size) + \n",
    "                \", Minibatch Loss = {:.6f}\".format(train_loss) + \n",
    "                \", Training Accuracy = {:.5f}\".format(train_acc) + \n",
    "                \", Test Accuracy = {:.5f}\".format(test_acc)\n",
    "             )\n",
    "\n",
    "        step += 1\n",
    "        \n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "train_writer.close()\n",
    "test_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "test_dataset = data_manager.get_test_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a batch of training examples\n",
    "test_batch_x, test_batch_y = test_dataset.next_batch(5)\n",
    "\n",
    "# Run test\n",
    "print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: test_batch_x, y: test_batch_y, keep_prob: 1.}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
