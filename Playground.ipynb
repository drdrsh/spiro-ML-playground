{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import Dataset\n",
    "from   ModelLoader import ModelLoader\n",
    "from convnet import *\n",
    "import datetime\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Testing TF GPU Support\n",
    "\n",
    "# Creates a graph.\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "test_sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(test_sess.run(c))\n",
    "test_sess.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after conv1[85 85 85]\n",
      "after maxpool1[ 40.  40.  40.]\n",
      "after conv2[ 40.  40.  40.]\n",
      "after maxpool2[ 17.  17.  17.]\n",
      "[3, 3, 3, 1, 32]\n",
      "[3, 3, 3, 32, 32]\n",
      "[3, 3, 3, 32, 32]\n",
      "[157216, 256]\n",
      "Loading dataset /home/mostafa/BigSpiroData/train/raw_augmented_np/6/data_4.npy (sync) \n",
      "Loaded dataset /home/mostafa/BigSpiroData/train/raw_augmented_np/6/data_4.npy of the shape (170, 614125)\n",
      "Loading dataset /home/mostafa/BigSpiroData/train/raw_augmented_np/6/data_15.npy (async) \n",
      "Loaded dataset /home/mostafa/BigSpiroData/train/raw_augmented_np/6/data_15.npy of the shape (170, 614125)\n"
     ]
    }
   ],
   "source": [
    "model = ModelLoader('models/model_1.json')\n",
    "\n",
    "data_manager = Dataset.DatasetManager(\n",
    "    train=model.get_config('train_data_path'),\n",
    "    test= model.get_config('test_data_path'),\n",
    "    target_shape=model.get_config('data_shape')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85, 85, 85]\n",
      "Input to Conv1 (?, 85, 85, 85, 1)\n",
      "Output of Conv1 (?, 85, 85, 85, 32)\n",
      "Input to MaxPool1 (?, 85, 85, 85, 32)\n",
      "Output of MaxPool1 (?, 40, 40, 40, 32)\n",
      "Input to Conv2 (?, 40, 40, 40, 32)\n",
      "Output of Conv2 (?, 40, 40, 40, 32)\n",
      "Input to MaxPool2 (?, 40, 40, 40, 32)\n",
      "Output to MaxPool2 (?, 17, 17, 17, 32)\n",
      "Loading dataset /home/mostafa/BigSpiroData/test/raw_np/6/data_0.npy (sync) \n",
      "Loaded dataset /home/mostafa/BigSpiroData/test/raw_np/6/data_0.npy of the shape (12, 614125)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "ds = data_manager.get_current_dataset()\n",
    "\n",
    "# Network Parameters\n",
    "data_shape = [ds.original_X_shape[1], ds.original_X_shape[2], ds.original_X_shape[3]]\n",
    "n_input   = ds.original_X_shape[1] * ds.original_X_shape[2] * ds.original_X_shape[3]   # Input size\n",
    "n_classes = model.get_config('n_classes')\n",
    "dropout   = model.get_config('dropout')\n",
    "\n",
    "# Parameters\n",
    "learning_rate  = model.get_config('learning_rate')\n",
    "training_iters = model.get_config('training_iters')\n",
    "batch_size     = model.get_config('batch_size')\n",
    "display_step   = model.get_config('display_step')\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "\n",
    "with tf.name_scope('dropout'):\n",
    "    keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "    tf.scalar_summary('dropout_keep_probability', keep_prob)\n",
    "    \n",
    "# Construct model\n",
    "pred = conv_net(x, data_shape, model.get_weights(), model.get_biases(), keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    with tf.name_scope('total'):\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "        tf.scalar_summary('cost', cost)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "with tf.name_scope('accuracy'):\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    tf.scalar_summary('accuracy', accuracy)\n",
    "\n",
    "# Initializing the variables\n",
    "merged = tf.merge_all_summaries()\n",
    "\n",
    "str_now = datetime.datetime.now().strftime(\"%d-%m-%Y#%H_%M_%S\")\n",
    "\n",
    "train_writer = tf.train.SummaryWriter('logs/train/' + '/' + model.get_config('id') +  str_now, sess.graph)\n",
    "test_writer  = tf.train.SummaryWriter('logs/test/'  + '/' + model.get_config('id') +  str_now, sess.graph)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)\n",
    "\n",
    "# Load test dataset\n",
    "test_dataset = data_manager.get_test_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.050311606377363205"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 8 * 25 * (64 * 64 * 64 * 1 ) + (5 * 5 * 5 * 1 * 12 ) + (5 * 5 * 5 * 12 * 12) + (8 * 8 * 8 * 12 * 256) + (256 * 2)\n",
    "\n",
    "x / (1024 * 1024  * 1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 30, Minibatch Loss = 596521.187500, Training Accuracy = 1.00000, Test Accuracy = 1.00000\n",
      "Iter 60, Minibatch Loss = 179687.343750, Training Accuracy = 0.33333, Test Accuracy = 1.00000\n",
      "Iter 90, Minibatch Loss = 838276.000000, Training Accuracy = 0.00000, Test Accuracy = 0.00000\n",
      "Iter 120, Minibatch Loss = 781900.000000, Training Accuracy = 1.00000, Test Accuracy = 1.00000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-3de3f19981b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# Run optimization op (backprop)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmerged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mtrain_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mostafa/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 382\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    383\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mostafa/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 655\u001b[1;33m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mostafa/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 723\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    724\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/mostafa/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    728\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mostafa/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    710\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m    711\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 712\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "step = 1\n",
    "\n",
    "with sess:\n",
    "    \n",
    "    test_batch_x, test_batch_y = test_dataset.next_batch(4)\n",
    "    test_dict = {\n",
    "        x: test_batch_x,\n",
    "        y: test_batch_y,\n",
    "        keep_prob: 1.0\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "\n",
    "        batch_x, batch_y = data_manager.next_batch(batch_size)\n",
    "        train_dict = {\n",
    "            x: batch_x, \n",
    "            y: batch_y, \n",
    "            keep_prob: 1.0\n",
    "        }\n",
    "                        \n",
    "        # Run optimization op (backprop)\n",
    "        summary, _ = sess.run([merged, optimizer], feed_dict=train_dict)\n",
    "        train_writer.add_summary(summary, step)\n",
    "\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            train_acc, train_loss = sess.run([accuracy, cost], feed_dict=train_dict)\n",
    "            summary, test_acc  = sess.run([merged, accuracy], feed_dict=test_dict)\n",
    "\n",
    "            test_writer.add_summary(summary, step)\n",
    "            \n",
    "            print( \"Iter \" + str(step * batch_size) + \n",
    "                \", Minibatch Loss = {:.6f}\".format(train_loss) + \n",
    "                \", Training Accuracy = {:.5f}\".format(train_acc) + \n",
    "                \", Test Accuracy = {:.5f}\".format(test_acc)\n",
    "             )\n",
    "\n",
    "        step += 1\n",
    "        \n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "train_writer.close()\n",
    "test_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "test_dataset = data_manager.get_test_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a batch of training examples\n",
    "test_batch_x, test_batch_y = test_dataset.next_batch(5)\n",
    "\n",
    "# Run test\n",
    "print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: test_batch_x, y: test_batch_y, keep_prob: 1.}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
